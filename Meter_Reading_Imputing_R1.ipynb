{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Modeling\n",
    "- First steps include:\n",
    "    - Add date columns\n",
    "    - impute missing electricity consumption values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('berkeley_matched_readings.pkl','rb') as read_file:\n",
    "    berkeley_df = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_df = berkeley_df.sort_values(by=['building_id', 'timestamp']).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add date, month, hour, day columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_time = [str(rows) for index, rows in berkeley_df['timestamp'].iteritems()]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that converts timestamp to datetime, then creates hour, day, month, and date series\n",
    "\n",
    "def to_datetime(time_list):\n",
    "\n",
    "    new_time_list = []\n",
    "\n",
    "    for i in time_list:\n",
    "        i = i.strip()\n",
    "        new_time_list.append(dt.datetime.strptime(i, '%Y-%m-%d %H:%M:%S'))\n",
    "    \n",
    "    hours = pd.Series(new_time_list).dt.hour\n",
    "    days = pd.Series(new_time_list).dt.day\n",
    "    months = pd.Series(new_time_list).dt.month\n",
    "    years = pd.Series(new_time_list).dt.year\n",
    "    date = pd.Series(new_time_list).dt.date\n",
    "    \n",
    "    return new_time_list, hours, days, months, years, date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_new_time, berkeley_hours, berkeley_days, berkeley_months, berkeley_years, berkeley_date = to_datetime(berkeley_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_df['timestamp'] = berkeley_new_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_df.insert(2, column = 'Date', value = berkeley_date)\n",
    "berkeley_df.insert(3, column = 'Month', value = berkeley_years)\n",
    "berkeley_df.insert(4, column = 'Year', value = berkeley_months)\n",
    "berkeley_df.insert(5, column = 'Day', value = berkeley_days)\n",
    "berkeley_df.insert(6, column = 'Hour', value = berkeley_hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add season column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and add season column:\n",
    "\n",
    "def season_helper(month):\n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    if month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    if month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Fall'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_df.insert(3, column = 'Season', value = berkeley_df['Month'].apply(season_helper))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>meter_reading_scraped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>565</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>565</td>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>565</td>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>565</td>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>565</td>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2539675</td>\n",
       "      <td>655</td>\n",
       "      <td>2019-11-30 19:00:00</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>127.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2539676</td>\n",
       "      <td>655</td>\n",
       "      <td>2019-11-30 20:00:00</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2539677</td>\n",
       "      <td>655</td>\n",
       "      <td>2019-11-30 21:00:00</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>121.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2539678</td>\n",
       "      <td>655</td>\n",
       "      <td>2019-11-30 22:00:00</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2539679</td>\n",
       "      <td>655</td>\n",
       "      <td>2019-11-30 23:00:00</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2539680 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         building_id           timestamp        Date Season  Month  Year  Day  \\\n",
       "0                565 2016-01-01 00:00:00  2016-01-01   Fall   2016     1    1   \n",
       "1                565 2016-01-01 01:00:00  2016-01-01   Fall   2016     1    1   \n",
       "2                565 2016-01-01 02:00:00  2016-01-01   Fall   2016     1    1   \n",
       "3                565 2016-01-01 03:00:00  2016-01-01   Fall   2016     1    1   \n",
       "4                565 2016-01-01 04:00:00  2016-01-01   Fall   2016     1    1   \n",
       "...              ...                 ...         ...    ...    ...   ...  ...   \n",
       "2539675          655 2019-11-30 19:00:00  2019-11-30   Fall   2019    11   30   \n",
       "2539676          655 2019-11-30 20:00:00  2019-11-30   Fall   2019    11   30   \n",
       "2539677          655 2019-11-30 21:00:00  2019-11-30   Fall   2019    11   30   \n",
       "2539678          655 2019-11-30 22:00:00  2019-11-30   Fall   2019    11   30   \n",
       "2539679          655 2019-11-30 23:00:00  2019-11-30   Fall   2019    11   30   \n",
       "\n",
       "         Hour  meter_reading_scraped  \n",
       "0           0                    8.0  \n",
       "1           1                    7.0  \n",
       "2           2                    8.0  \n",
       "3           3                    8.0  \n",
       "4           4                    8.0  \n",
       "...       ...                    ...  \n",
       "2539675    19                  127.0  \n",
       "2539676    20                  125.0  \n",
       "2539677    21                  121.0  \n",
       "2539678    22                  123.0  \n",
       "2539679    23                  122.0  \n",
       "\n",
       "[2539680 rows x 9 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berkeley_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing values\n",
    "- This notebook only looks at buildings that having few missing values (less than 10 consecutive NaN values at a time)\n",
    "- These values will be filled using ffill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataframe by the 74 buidlings.\n",
    "\n",
    "def building_df_separator(full_df, building_no):\n",
    "    \n",
    "    building_df = full_df[full_df['building_id'] == building_no]\n",
    "        \n",
    "    return building_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_list = berkeley_df['building_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([565, 567, 568, 569, 570, 571, 573, 574, 575, 576, 577, 580, 582,\n",
       "       583, 584, 585, 586, 587, 588, 589, 592, 594, 595, 597, 598, 599,\n",
       "       600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612,\n",
       "       614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 626, 627,\n",
       "       628, 630, 631, 632, 633, 634, 635, 636, 637, 638, 640, 641, 642,\n",
       "       643, 644, 645, 646, 649, 652, 653, 654, 655])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "building_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building_dict key: building number\n",
    "# building_dict value: buidling's berkeley dataframe\n",
    "\n",
    "building_dict = {}\n",
    "\n",
    "for i in building_list:\n",
    "    building_dict[i] = building_df_separator(berkeley_df, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>Date</th>\n",
       "      <th>Season</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "      <th>meter_reading_scraped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>137280</td>\n",
       "      <td>570</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>79.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137281</td>\n",
       "      <td>570</td>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137282</td>\n",
       "      <td>570</td>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>79.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137283</td>\n",
       "      <td>570</td>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>79.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137284</td>\n",
       "      <td>570</td>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>77.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171595</td>\n",
       "      <td>570</td>\n",
       "      <td>2019-11-30 19:00:00</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>162.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171596</td>\n",
       "      <td>570</td>\n",
       "      <td>2019-11-30 20:00:00</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>162.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171597</td>\n",
       "      <td>570</td>\n",
       "      <td>2019-11-30 21:00:00</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>160.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171598</td>\n",
       "      <td>570</td>\n",
       "      <td>2019-11-30 22:00:00</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>122.688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171599</td>\n",
       "      <td>570</td>\n",
       "      <td>2019-11-30 23:00:00</td>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2019</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>23</td>\n",
       "      <td>119.232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34320 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id           timestamp        Date Season  Month  Year  Day  \\\n",
       "137280          570 2016-01-01 00:00:00  2016-01-01   Fall   2016     1    1   \n",
       "137281          570 2016-01-01 01:00:00  2016-01-01   Fall   2016     1    1   \n",
       "137282          570 2016-01-01 02:00:00  2016-01-01   Fall   2016     1    1   \n",
       "137283          570 2016-01-01 03:00:00  2016-01-01   Fall   2016     1    1   \n",
       "137284          570 2016-01-01 04:00:00  2016-01-01   Fall   2016     1    1   \n",
       "...             ...                 ...         ...    ...    ...   ...  ...   \n",
       "171595          570 2019-11-30 19:00:00  2019-11-30   Fall   2019    11   30   \n",
       "171596          570 2019-11-30 20:00:00  2019-11-30   Fall   2019    11   30   \n",
       "171597          570 2019-11-30 21:00:00  2019-11-30   Fall   2019    11   30   \n",
       "171598          570 2019-11-30 22:00:00  2019-11-30   Fall   2019    11   30   \n",
       "171599          570 2019-11-30 23:00:00  2019-11-30   Fall   2019    11   30   \n",
       "\n",
       "        Hour  meter_reading_scraped  \n",
       "137280     0                 79.488  \n",
       "137281     1                 79.488  \n",
       "137282     2                 79.488  \n",
       "137283     3                 79.488  \n",
       "137284     4                 77.760  \n",
       "...      ...                    ...  \n",
       "171595    19                162.432  \n",
       "171596    20                162.432  \n",
       "171597    21                160.704  \n",
       "171598    22                122.688  \n",
       "171599    23                119.232  \n",
       "\n",
       "[34320 rows x 9 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "building_dict[570]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find highest number of consecutive NaN values for each building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def na_count(na_dict):\n",
    "    \n",
    "    na_count_list = []\n",
    "    \n",
    "    for i in building_list:\n",
    "        na_count = na_dict[i].meter_reading_scraped.isnull().astype(int).groupby(na_dict[i].meter_reading_scraped.notnull().astype(int).cumsum()).cumsum()\n",
    "        na_count_list.append([i, na_count.sort_values(ascending=False).values[0]])\n",
    "        \n",
    "    return na_count_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_na_count = na_count(building_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Small NaN gap = less than 10 consecutive missing values**  \n",
    "**Big NaN gap = 10 or more consecutive missing values**\n",
    "- Reduce berkeley_df to only buildings with small NaN gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_na_gap = [i[0] for i in building_na_count if i[1] > 9]\n",
    "small_na_gap = [i[0] for i in building_na_count if i[1] < 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_or_small = []\n",
    "\n",
    "for index, rows in berkeley_df['building_id'].iteritems():\n",
    "    if rows in small_na_gap:\n",
    "        big_or_small.append('Small')\n",
    "    elif rows in big_na_gap:\n",
    "        big_or_small.append('Big')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2539680"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(big_or_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_df['Big_or_Small'] = big_or_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_small_df = berkeley_df[berkeley_df['Big_or_Small'] == 'Small']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_small_dict = {}\n",
    "\n",
    "for i in small_na_gap:\n",
    "    building_small_dict[i] = building_df_separator(berkeley_small_df, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replace NaN values in berkeley_small_df using ffill method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrewgraves/anaconda3/envs/metis/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for keys, values in building_small_dict.items():\n",
    "    values['meter_reading_scraped'] = values['meter_reading_scraped'].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley_small_clean = building_small_dict[565]\n",
    "\n",
    "for i in small_na_gap[1:]:\n",
    "    berkeley_small_clean = berkeley_small_clean.append(building_small_dict[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1372778\n",
       "True          22\n",
       "Name: meter_reading_scraped, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berkeley_small_df['meter_reading_scraped'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1372800\n",
       "Name: meter_reading_scraped, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berkeley_small_clean['meter_reading_scraped'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_na_index = berkeley_small_df[berkeley_small_df['meter_reading_scraped'].isna() == True].index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_na_series = berkeley_small_clean['meter_reading_scraped'].loc[small_na_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34190         1.110974\n",
       "155435      208.742400\n",
       "509619      148.714280\n",
       "509620      148.714280\n",
       "509621      148.714280\n",
       "509622      148.714280\n",
       "509623      148.714280\n",
       "510751       -9.925496\n",
       "510752       -9.925496\n",
       "510753       -9.925496\n",
       "1082075      45.090908\n",
       "1287995     544.933350\n",
       "1322315      98.909090\n",
       "1631195     258.400000\n",
       "1768475     139.600000\n",
       "1837115      76.400000\n",
       "2317595    1612.091600\n",
       "2351915      84.000000\n",
       "2386235     385.636350\n",
       "2420555     233.526370\n",
       "2489195      56.666668\n",
       "2523515     179.266660\n",
       "Name: meter_reading_scraped, dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_na_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('small_na_series.pkl', 'wb') as to_write:\n",
    "#     pickle.dump(small_na_series, to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
